"""
FastAPI ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List, Optional
from pydantic import BaseModel
from datetime import datetime

from database import get_db, init_db, create_article, get_article_by_url, update_article_analysis
from database import add_to_post_queue, get_pending_posts
from gemini_analyzer import GeminiAnalyzer
from gemini_researcher import GeminiResearcher
from twitter_poster import SocialPoster
from article_fetcher import ArticleFetcher, RSSFeedManager, get_default_feed_manager
from url_shortener import URLShortener
from auth import BasicAuthMiddleware, AUTH_ENABLED, verify_post_password
from models import Article, PostQueue
from scheduler import ArticleScheduler
import threading

# FastAPIã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = FastAPI(title="Weak Signals App", version="1.0.0")

# Basicèªè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ï¼ˆCORSã‚ˆã‚Šå‰ã«è¿½åŠ ï¼‰
if AUTH_ENABLED:
    app.add_middleware(BasicAuthMiddleware)
    print("ğŸ” Basicèªè¨¼ãŒæœ‰åŠ¹ã§ã™")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ã«è¨­å®š
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
init_db()

# ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã¨ãƒã‚¹ã‚¿ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
analyzer = GeminiAnalyzer()
try:
    researcher = GeminiResearcher()
except Exception as e:
    print(f"âš ï¸ GeminiResearcheråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    researcher = None

try:
    poster = SocialPoster()
except Exception as e:
    print(f"âš ï¸ ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    poster = None

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–ã¨èµ·å‹•ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
try:
    scheduler = ArticleScheduler()
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§èµ·å‹•
    scheduler_thread = threading.Thread(target=scheduler.run_scheduler, args=(15,), daemon=True)
    scheduler_thread.start()
    print("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•ã—ã¾ã—ãŸï¼ˆ15åˆ†é–“éš”ï¼‰")
except Exception as e:
    print(f"âš ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()

# è¨˜äº‹å–å¾—ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
article_fetcher = ArticleFetcher()
feed_manager = get_default_feed_manager()

# URLçŸ­ç¸®ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
url_shortener = URLShortener()


# Pydanticãƒ¢ãƒ‡ãƒ«
class ArticleCreate(BaseModel):
    url: str
    title: str
    content: Optional[str] = None
    published_at: Optional[datetime] = None


class RSSFeedRequest(BaseModel):
    rss_url: str
    max_items: int = 10


class URLFetchRequest(BaseModel):
    urls: List[str]


class ThemeResearchRequest(BaseModel):
    themes: str  # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒ†ãƒ¼ãƒãƒªã‚¹ãƒˆï¼ˆä¾‹: "AI, ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³, é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿"ï¼‰


class PostRequest(BaseModel):
    confirm_password: str  # æŠ•ç¨¿ç¢ºèªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰


class ArticleResponse(BaseModel):
    id: int
    url: str
    title: str
    theme: Optional[str]
    summary: Optional[str]
    is_posted: bool
    
    class Config:
        from_attributes = True


class PostQueueResponse(BaseModel):
    id: int
    article_id: int
    post_text: str
    status: str
    created_at: datetime
    
    class Config:
        from_attributes = True


# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"message": "Weak Signals App API", "status": "running"}


@app.post("/articles", response_model=ArticleResponse)
async def create_article_endpoint(
    article: ArticleCreate,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ã‚’ä½œæˆ"""
    # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
    existing = get_article_by_url(db, article.url)
    if existing:
        raise HTTPException(status_code=400, detail="è¨˜äº‹ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # è¨˜äº‹ä½œæˆ
    db_article = create_article(
        db, article.url, article.title, article.content, article.published_at
    )
    
    return db_article


@app.post("/articles/{article_id}/analyze", response_model=ArticleResponse)
async def analyze_article_endpoint(
    article_id: int,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ã‚’åˆ†æ"""
    article = db.query(Article).filter(Article.id == article_id).first()
    if not article:
        raise HTTPException(status_code=404, detail="è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # Geminiã§åˆ†æ
    analysis = analyzer.analyze_article(article.title, article.content or "", article.url)
    
    # çµæœã‚’ä¿å­˜
    updated_article = update_article_analysis(db, article_id, analysis)
    
    # æŠ•ç¨¿å€™è£œã®å ´åˆã€ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    if analysis.get("should_post", False):
        # URLã‚’çŸ­ç¸®
        short_url = url_shortener.shorten(article.url)
        tweet_text = analyzer.generate_tweet_text(
            article.title, analysis.get("summary"), analysis.get("theme"), short_url
        )
        add_to_post_queue(db, article_id, tweet_text)
    
    return updated_article


@app.get("/articles", response_model=List[ArticleResponse])
async def list_articles(
    skip: int = 0,
    limit: int = 100,
    theme: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ä¸€è¦§ã‚’å–å¾—"""
    query = db.query(Article)
    
    if theme:
        query = query.filter(Article.theme == theme)
    
    articles = query.order_by(Article.created_at.desc()).offset(skip).limit(limit).all()
    return articles


@app.get("/articles/{article_id}", response_model=ArticleResponse)
async def get_article(article_id: int, db: Session = Depends(get_db)):
    """è¨˜äº‹ã‚’å–å¾—"""
    article = db.query(Article).filter(Article.id == article_id).first()
    if not article:
        raise HTTPException(status_code=404, detail="è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return article


@app.get("/post-queue", response_model=List[PostQueueResponse])
async def list_post_queue(
    status: Optional[str] = "pending",
    db: Session = Depends(get_db)
):
    """æŠ•ç¨¿ã‚­ãƒ¥ãƒ¼ã‚’å–å¾—"""
    query = db.query(PostQueue)
    if status:
        query = query.filter(PostQueue.status == status)
    
    queue_items = query.order_by(PostQueue.created_at.desc()).all()
    return queue_items


@app.post("/post-queue/{queue_id}/approve")
async def approve_post(
    queue_id: int,
    db: Session = Depends(get_db)
):
    """æŠ•ç¨¿ã‚’æ‰¿èª"""
    queue_item = db.query(PostQueue).filter(PostQueue.id == queue_id).first()
    if not queue_item:
        raise HTTPException(status_code=404, detail="ã‚­ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    queue_item.status = "approved"
    queue_item.approved_at = datetime.utcnow()
    db.commit()
    
    return {"message": "æ‰¿èªå®Œäº†", "queue_id": queue_id}


@app.post("/post-queue/{queue_id}/post")
async def post_to_social(
    queue_id: int,
    request: PostRequest,
    db: Session = Depends(get_db)
):
    """ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã«æŠ•ç¨¿ï¼ˆæŠ•ç¨¿ç¢ºèªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¿…è¦ï¼‰"""
    if not poster:
        raise HTTPException(status_code=503, detail="ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢è¨­å®šãŒã‚ã‚Šã¾ã›ã‚“")
    
    # æŠ•ç¨¿ç¢ºèªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œè¨¼
    if not verify_post_password(request.confirm_password):
        raise HTTPException(status_code=403, detail="æŠ•ç¨¿ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
    
    queue_item = db.query(PostQueue).filter(PostQueue.id == queue_id).first()
    if not queue_item:
        raise HTTPException(status_code=404, detail="ã‚­ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã«æŠ•ç¨¿
    result = poster.post(queue_item.post_text)
    if not result:
        raise HTTPException(status_code=500, detail="æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
    queue_item.status = "posted"
    article = db.query(Article).filter(Article.id == queue_item.article_id).first()
    if article:
        article.is_posted = True
        article.posted_at = datetime.utcnow()
        article.tweet_id = result.get("post_id")  # post_idã«çµ±ä¸€
    
    db.commit()
    
    return {"message": "æŠ•ç¨¿å®Œäº†", "post_id": result.get("post_id"), "platform": result.get("platform")}


@app.get("/healthz")
async def health_check():
    """è»½é‡ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆRenderç”¨ï¼‰"""
    return {"status": "ok"}


@app.get("/stats")
async def get_stats(db: Session = Depends(get_db)):
    """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    total_articles = db.query(Article).count()
    posted_articles = db.query(Article).filter(Article.is_posted == True).count()
    pending_posts = db.query(PostQueue).filter(PostQueue.status == "pending").count()
    
    # ãƒ†ãƒ¼ãƒåˆ¥é›†è¨ˆ
    themes = db.query(Article.theme).distinct().all()
    theme_count = len([t for t in themes if t[0]])
    
    return {
        "total_articles": total_articles,
        "posted_articles": posted_articles,
        "pending_posts": pending_posts,
        "themes": theme_count
    }


@app.post("/fetch/rss")
async def fetch_from_rss(
    request: RSSFeedRequest,
    db: Session = Depends(get_db)
):
    """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
    try:
        articles = article_fetcher.fetch_from_rss(request.rss_url, request.max_items)
        
        created_count = 0
        for article_data in articles:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, article_data['url'])
            if not existing:
                create_article(
                    db,
                    article_data['url'],
                    article_data['title'],
                    article_data.get('content'),
                    article_data.get('published_at')
                )
                created_count += 1
        
        return {
            "message": "è¨˜äº‹å–å¾—å®Œäº†",
            "fetched": len(articles),
            "created": created_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")


@app.post("/fetch/url")
async def fetch_from_url(
    request: URLFetchRequest,
    db: Session = Depends(get_db)
):
    """URLã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
    try:
        articles = article_fetcher.fetch_from_urls(request.urls)
        
        created_count = 0
        for article_data in articles:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, article_data['url'])
            if not existing:
                create_article(
                    db,
                    article_data['url'],
                    article_data['title'],
                    article_data.get('content'),
                    article_data.get('published_at')
                )
                created_count += 1
        
        return {
            "message": "è¨˜äº‹å–å¾—å®Œäº†",
            "fetched": len(articles),
            "created": created_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")


@app.post("/fetch/research")
async def fetch_by_research(
    request: ThemeResearchRequest,
    db: Session = Depends(get_db)
):
    """Gemini Groundingï¼ˆGoogle Searchï¼‰ã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’å–å¾—ãƒ»åˆ†æ"""
    if not researcher:
        raise HTTPException(status_code=503, detail="GeminiResearcherãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    try:
        # DeepResearchã§è¨˜äº‹ã‚’å–å¾—
        articles = researcher.fetch_articles_by_themes(request.themes)
    except ValueError as e:
        # toolsã®äºŒé‡æŒ‡å®šãªã©ã®å®Ÿè£…ãƒŸã‚¹ã¯400ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦è¿”ã™
        if "tools specified multiple times" in str(e):
            raise HTTPException(status_code=400, detail=str(e))
        raise
    except RuntimeError as e:
        # toolsãŒäºŒé‡ã«æ¸¡ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆ
        if "tools would be passed twice" in str(e):
            raise HTTPException(status_code=400, detail="Invalid request: tools specified multiple times")
        raise
    except Exception as e:
        # Gemini APIã®503/429/500ã‚¨ãƒ©ãƒ¼ã‚’é©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        error_str = str(e).lower()
        
        # 503ã‚¨ãƒ©ãƒ¼ï¼ˆã‚µãƒ¼ãƒ“ã‚¹ä¸€æ™‚åˆ©ç”¨ä¸å¯ï¼‰
        if "503" in error_str or "service unavailable" in error_str:
            headers = {"Retry-After": "10"}
            raise HTTPException(
                status_code=503,
                detail="Upstream service temporarily unavailable. Please retry later.",
                headers=headers
            )
        
        # 429ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
        if "429" in error_str or "rate limit" in error_str or "quota" in error_str or "resource exhausted" in error_str:
            headers = {"Retry-After": "60"}
            raise HTTPException(
                status_code=429,
                detail="Rate limit exceeded. Please retry later.",
                headers=headers
            )
        
        # 500ã‚¨ãƒ©ãƒ¼ï¼ˆã‚µãƒ¼ãƒãƒ¼å†…éƒ¨ã‚¨ãƒ©ãƒ¼ï¼‰
        if "500" in error_str or "internal server error" in error_str:
            raise HTTPException(
                status_code=502,  # Bad Gatewayï¼ˆä¸Šæµã®ã‚¨ãƒ©ãƒ¼ï¼‰
                detail="Upstream service error. Please retry later."
            )
        
        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯500ã¨ã—ã¦è¿”ã™
        raise HTTPException(status_code=500, detail=f"Internal error: {str(e)}")
    
    try:
        processed_count = 0
        analyzed_count = 0
        queued_count = 0
        
        for article_data in articles:
            url = article_data['url']
            title = article_data['title']
            content = article_data.get('content', '')
            
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, url)
            if existing:
                continue
            
            # è¨˜äº‹ä½œæˆ
            article = create_article(
                db,
                url,
                title,
                content,
                article_data.get('published_at')
            )
            processed_count += 1
            
            # ãƒ†ãƒ¼ãƒãŒæ—¢ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨ã€ãªã‘ã‚Œã°åˆ†æ
            if article_data.get('theme'):
                # DeepResearchã§æ—¢ã«ãƒ†ãƒ¼ãƒãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
                analysis = {
                    "theme": article_data.get('theme'),
                    "summary": article_data.get('summary', ''),
                    "key_points": '[]',
                    "sentiment_score": 0.7,  # Weak Signalãªã®ã§ä¸­ç«‹çš„ã«é«˜ã‚
                    "relevance_score": 0.9,  # Weak Signalãªã®ã§é–¢é€£æ€§ãŒé«˜ã„
                    "should_post": True  # Weak Signalãªã®ã§æŠ•ç¨¿å€™è£œ
                }
                update_article_analysis(db, article.id, analysis)
                analyzed_count += 1
                
                # æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆæœªæ¥ã®å…†ã—ã‚’å«ã‚ã‚‹ï¼‰
                # URLã‚’çŸ­ç¸®
                short_url = url_shortener.shorten(url)
                future_signal = article_data.get('future_signal', '')
                summary = article_data.get('summary', '')
                
                # 280æ–‡å­—ä»¥å†…ã«åã‚ã‚‹ï¼ˆURLå«ã‚€ï¼‰
                # æ§‹é€ : ã‚¿ã‚¤ãƒˆãƒ« â†’ è¦ç´„ â†’ URL â†’ æœªæ¥ã®å…†ã—
                url_length = len(short_url) + 2  # +2ã¯æ”¹è¡Œåˆ†
                future_label = "ğŸ”® æœªæ¥ã®å…†ã—: "
                future_length = len(future_label) + len(future_signal) + 2  # +2ã¯æ”¹è¡Œåˆ†
                title_length = len(title) + 2  # +2ã¯æ”¹è¡Œåˆ†
                
                # è¦ç´„ã®æœ€å¤§é•·ã‚’è¨ˆç®—
                max_summary_length = 280 - title_length - url_length - future_length - 10  # ä½™è£•ã‚’æŒãŸã›ã‚‹
                
                if max_summary_length < 0:
                    # æ–‡å­—æ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯è¦ç´„ã‚’çŸ­ç¸®
                    max_summary_length = 50
                
                if len(summary) > max_summary_length:
                    summary = summary[:max_summary_length - 3] + "..."
                
                # æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
                post_text = f"{title}\n\n{summary}\n\n{short_url}\n\n{future_label}{future_signal}"
                
                # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ï¼ˆ280æ–‡å­—ä»¥å†…ï¼‰
                if len(post_text) > 280:
                    # æœªæ¥ã®å…†ã—ã‚’çŸ­ç¸®
                    remaining_length = 280 - len(f"{title}\n\n{summary}\n\n{short_url}\n\n{future_label}")
                    if remaining_length > 0:
                        future_signal = future_signal[:remaining_length - 3] + "..."
                        post_text = f"{title}\n\n{summary}\n\n{short_url}\n\n{future_label}{future_signal}"
                    else:
                        # ãã‚Œã§ã‚‚é•·ã„å ´åˆã¯è¦ç´„ã‚’ã•ã‚‰ã«çŸ­ç¸®
                        max_summary_length = 280 - title_length - url_length - len(future_label) - 20
                        summary = summary[:max_summary_length - 3] + "..."
                        post_text = f"{title}\n\n{summary}\n\n{short_url}\n\n{future_label}{future_signal[:50]}"
                
                add_to_post_queue(db, article.id, post_text)
                queued_count += 1
            else:
                # ãƒ†ãƒ¼ãƒãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯åˆ†æã‚’å®Ÿè¡Œ
                try:
                    analysis = analyzer.analyze_article(title, content, url)
                    update_article_analysis(db, article.id, analysis)
                    analyzed_count += 1
                    
                    # æŠ•ç¨¿å€™è£œã®å ´åˆã€ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    if analysis.get("should_post", False):
                        # URLã‚’çŸ­ç¸®
                        short_url = url_shortener.shorten(url)
                        tweet_text = analyzer.generate_tweet_text(
                            title, analysis.get("summary"), analysis.get("theme"), short_url
                        )
                        add_to_post_queue(db, article.id, tweet_text)
                        queued_count += 1
                except Exception as e:
                    print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        return {
            "message": "DeepResearchå–å¾—ãƒ»åˆ†æå®Œäº†",
            "processed": processed_count,
            "analyzed": analyzed_count,
            "queued": queued_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¨ãƒ©ãƒ¼: {str(e)}")


@app.post("/fetch/analyze")
async def fetch_and_analyze(
    rss_url: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ã‚’å–å¾—ã—ã¦è‡ªå‹•åˆ†æï¼ˆRSSãƒ•ã‚£ãƒ¼ãƒ‰ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"""
    try:
        if rss_url:
            # æŒ‡å®šã•ã‚ŒãŸRSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å–å¾—
            articles = article_fetcher.fetch_from_rss(rss_url)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å–å¾—
            articles = feed_manager.fetch_all_feeds()
        
        processed_count = 0
        analyzed_count = 0
        queued_count = 0
        
        for article_data in articles:
            url = article_data['url']
            title = article_data['title']
            content = article_data.get('content', '')
            
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, url)
            if existing:
                continue
            
            # è¨˜äº‹ä½œæˆ
            article = create_article(
                db,
                url,
                title,
                content,
                article_data.get('published_at')
            )
            processed_count += 1
            
            # åˆ†æ
            try:
                analysis = analyzer.analyze_article(title, content, url)
                update_article_analysis(db, article.id, analysis)
                analyzed_count += 1
                
                # æŠ•ç¨¿å€™è£œã®å ´åˆã€ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                if analysis.get("should_post", False):
                    # URLã‚’çŸ­ç¸®
                    short_url = url_shortener.shorten(url)
                    tweet_text = analyzer.generate_tweet_text(
                        title, analysis.get("summary"), analysis.get("theme"), short_url
                    )
                    add_to_post_queue(db, article.id, tweet_text)
                    queued_count += 1
            except Exception as e:
                print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return {
            "message": "å–å¾—ãƒ»åˆ†æå®Œäº†",
            "processed": processed_count,
            "analyzed": analyzed_count,
            "queued": queued_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¨ãƒ©ãƒ¼: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

