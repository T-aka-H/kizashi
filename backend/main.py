"""
FastAPI ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List, Optional
from pydantic import BaseModel
from datetime import datetime

from database import get_db, init_db, create_article, get_article_by_url, update_article_analysis
from database import add_to_post_queue, get_pending_posts
from gemini_analyzer import GeminiAnalyzer
from gemini_researcher import GeminiResearcher
from twitter_poster import SocialPoster
from article_fetcher import ArticleFetcher, RSSFeedManager, get_default_feed_manager
from url_shortener import URLShortener
from models import Article, PostQueue

# FastAPIã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = FastAPI(title="Weak Signals App", version="1.0.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ã«è¨­å®š
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
init_db()

# ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã¨ãƒã‚¹ã‚¿ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
analyzer = GeminiAnalyzer()
try:
    researcher = GeminiResearcher()
except Exception as e:
    print(f"âš ï¸ GeminiResearcheråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    researcher = None

try:
    poster = SocialPoster()
except Exception as e:
    print(f"âš ï¸ ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    poster = None

# è¨˜äº‹å–å¾—ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
article_fetcher = ArticleFetcher()
feed_manager = get_default_feed_manager()

# URLçŸ­ç¸®ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
url_shortener = URLShortener()


# Pydanticãƒ¢ãƒ‡ãƒ«
class ArticleCreate(BaseModel):
    url: str
    title: str
    content: Optional[str] = None
    published_at: Optional[datetime] = None


class RSSFeedRequest(BaseModel):
    rss_url: str
    max_items: int = 10


class URLFetchRequest(BaseModel):
    urls: List[str]


class ThemeResearchRequest(BaseModel):
    themes: str  # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒ†ãƒ¼ãƒãƒªã‚¹ãƒˆï¼ˆä¾‹: "AI, ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³, é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿"ï¼‰


class ArticleResponse(BaseModel):
    id: int
    url: str
    title: str
    theme: Optional[str]
    summary: Optional[str]
    is_posted: bool
    
    class Config:
        from_attributes = True


class PostQueueResponse(BaseModel):
    id: int
    article_id: int
    post_text: str
    status: str
    created_at: datetime
    
    class Config:
        from_attributes = True


# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"message": "Weak Signals App API", "status": "running"}


@app.post("/articles", response_model=ArticleResponse)
async def create_article_endpoint(
    article: ArticleCreate,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ã‚’ä½œæˆ"""
    # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
    existing = get_article_by_url(db, article.url)
    if existing:
        raise HTTPException(status_code=400, detail="è¨˜äº‹ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # è¨˜äº‹ä½œæˆ
    db_article = create_article(
        db, article.url, article.title, article.content, article.published_at
    )
    
    return db_article


@app.post("/articles/{article_id}/analyze", response_model=ArticleResponse)
async def analyze_article_endpoint(
    article_id: int,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ã‚’åˆ†æ"""
    article = db.query(Article).filter(Article.id == article_id).first()
    if not article:
        raise HTTPException(status_code=404, detail="è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # Geminiã§åˆ†æ
    analysis = analyzer.analyze_article(article.title, article.content or "", article.url)
    
    # çµæœã‚’ä¿å­˜
    updated_article = update_article_analysis(db, article_id, analysis)
    
    # æŠ•ç¨¿å€™è£œã®å ´åˆã€ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    if analysis.get("should_post", False):
        # URLã‚’çŸ­ç¸®
        short_url = url_shortener.shorten(article.url)
        tweet_text = analyzer.generate_tweet_text(
            article.title, analysis.get("summary"), analysis.get("theme"), short_url
        )
        add_to_post_queue(db, article_id, tweet_text)
    
    return updated_article


@app.get("/articles", response_model=List[ArticleResponse])
async def list_articles(
    skip: int = 0,
    limit: int = 100,
    theme: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ä¸€è¦§ã‚’å–å¾—"""
    query = db.query(Article)
    
    if theme:
        query = query.filter(Article.theme == theme)
    
    articles = query.order_by(Article.created_at.desc()).offset(skip).limit(limit).all()
    return articles


@app.get("/articles/{article_id}", response_model=ArticleResponse)
async def get_article(article_id: int, db: Session = Depends(get_db)):
    """è¨˜äº‹ã‚’å–å¾—"""
    article = db.query(Article).filter(Article.id == article_id).first()
    if not article:
        raise HTTPException(status_code=404, detail="è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return article


@app.get("/post-queue", response_model=List[PostQueueResponse])
async def list_post_queue(
    status: Optional[str] = "pending",
    db: Session = Depends(get_db)
):
    """æŠ•ç¨¿ã‚­ãƒ¥ãƒ¼ã‚’å–å¾—"""
    query = db.query(PostQueue)
    if status:
        query = query.filter(PostQueue.status == status)
    
    queue_items = query.order_by(PostQueue.created_at.desc()).all()
    return queue_items


@app.post("/post-queue/{queue_id}/approve")
async def approve_post(
    queue_id: int,
    db: Session = Depends(get_db)
):
    """æŠ•ç¨¿ã‚’æ‰¿èª"""
    queue_item = db.query(PostQueue).filter(PostQueue.id == queue_id).first()
    if not queue_item:
        raise HTTPException(status_code=404, detail="ã‚­ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    queue_item.status = "approved"
    queue_item.approved_at = datetime.utcnow()
    db.commit()
    
    return {"message": "æ‰¿èªå®Œäº†", "queue_id": queue_id}


@app.post("/post-queue/{queue_id}/post")
async def post_to_social(
    queue_id: int,
    db: Session = Depends(get_db)
):
    """ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã«æŠ•ç¨¿"""
    if not poster:
        raise HTTPException(status_code=503, detail="ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢è¨­å®šãŒã‚ã‚Šã¾ã›ã‚“")
    
    queue_item = db.query(PostQueue).filter(PostQueue.id == queue_id).first()
    if not queue_item:
        raise HTTPException(status_code=404, detail="ã‚­ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã«æŠ•ç¨¿
    result = poster.post(queue_item.post_text)
    if not result:
        raise HTTPException(status_code=500, detail="æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
    queue_item.status = "posted"
    article = db.query(Article).filter(Article.id == queue_item.article_id).first()
    if article:
        article.is_posted = True
        article.posted_at = datetime.utcnow()
        article.tweet_id = result.get("post_id")  # post_idã«çµ±ä¸€
    
    db.commit()
    
    return {"message": "æŠ•ç¨¿å®Œäº†", "post_id": result.get("post_id"), "platform": result.get("platform")}


@app.get("/stats")
async def get_stats(db: Session = Depends(get_db)):
    """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    total_articles = db.query(Article).count()
    posted_articles = db.query(Article).filter(Article.is_posted == True).count()
    pending_posts = db.query(PostQueue).filter(PostQueue.status == "pending").count()
    
    # ãƒ†ãƒ¼ãƒåˆ¥é›†è¨ˆ
    themes = db.query(Article.theme).distinct().all()
    theme_count = len([t for t in themes if t[0]])
    
    return {
        "total_articles": total_articles,
        "posted_articles": posted_articles,
        "pending_posts": pending_posts,
        "themes": theme_count
    }


@app.post("/fetch/rss")
async def fetch_from_rss(
    request: RSSFeedRequest,
    db: Session = Depends(get_db)
):
    """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
    try:
        articles = article_fetcher.fetch_from_rss(request.rss_url, request.max_items)
        
        created_count = 0
        for article_data in articles:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, article_data['url'])
            if not existing:
                create_article(
                    db,
                    article_data['url'],
                    article_data['title'],
                    article_data.get('content'),
                    article_data.get('published_at')
                )
                created_count += 1
        
        return {
            "message": "è¨˜äº‹å–å¾—å®Œäº†",
            "fetched": len(articles),
            "created": created_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")


@app.post("/fetch/url")
async def fetch_from_url(
    request: URLFetchRequest,
    db: Session = Depends(get_db)
):
    """URLã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
    try:
        articles = article_fetcher.fetch_from_urls(request.urls)
        
        created_count = 0
        for article_data in articles:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, article_data['url'])
            if not existing:
                create_article(
                    db,
                    article_data['url'],
                    article_data['title'],
                    article_data.get('content'),
                    article_data.get('published_at')
                )
                created_count += 1
        
        return {
            "message": "è¨˜äº‹å–å¾—å®Œäº†",
            "fetched": len(articles),
            "created": created_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")


@app.post("/fetch/research")
async def fetch_by_research(
    request: ThemeResearchRequest,
    db: Session = Depends(get_db)
):
    """Gemini DeepResearchã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’å–å¾—ãƒ»åˆ†æ"""
    if not researcher:
        raise HTTPException(status_code=503, detail="GeminiResearcherãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    try:
        # DeepResearchã§è¨˜äº‹ã‚’å–å¾—
        articles = researcher.fetch_articles_by_themes(request.themes)
        
        processed_count = 0
        analyzed_count = 0
        queued_count = 0
        
        for article_data in articles:
            url = article_data['url']
            title = article_data['title']
            content = article_data.get('content', '')
            
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, url)
            if existing:
                continue
            
            # è¨˜äº‹ä½œæˆ
            article = create_article(
                db,
                url,
                title,
                content,
                article_data.get('published_at')
            )
            processed_count += 1
            
            # ãƒ†ãƒ¼ãƒãŒæ—¢ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨ã€ãªã‘ã‚Œã°åˆ†æ
            if article_data.get('theme'):
                # DeepResearchã§æ—¢ã«ãƒ†ãƒ¼ãƒãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
                analysis = {
                    "theme": article_data.get('theme'),
                    "summary": article_data.get('summary', ''),
                    "key_points": '[]',
                    "sentiment_score": 0.7,  # Weak Signalãªã®ã§ä¸­ç«‹çš„ã«é«˜ã‚
                    "relevance_score": 0.9,  # Weak Signalãªã®ã§é–¢é€£æ€§ãŒé«˜ã„
                    "should_post": True  # Weak Signalãªã®ã§æŠ•ç¨¿å€™è£œ
                }
                update_article_analysis(db, article.id, analysis)
                analyzed_count += 1
                
                # æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆæœªæ¥ã®å…†ã—ã‚’å«ã‚ã‚‹ï¼‰
                # URLã‚’çŸ­ç¸®
                short_url = url_shortener.shorten(url)
                future_signal = article_data.get('future_signal', '')
                post_text = f"{title}\n\n{article_data.get('summary', '')}\n\nğŸ”® æœªæ¥ã®å…†ã—: {future_signal}\n\n{short_url}"
                add_to_post_queue(db, article.id, post_text)
                queued_count += 1
            else:
                # ãƒ†ãƒ¼ãƒãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯åˆ†æã‚’å®Ÿè¡Œ
                try:
                    analysis = analyzer.analyze_article(title, content, url)
                    update_article_analysis(db, article.id, analysis)
                    analyzed_count += 1
                    
                    # æŠ•ç¨¿å€™è£œã®å ´åˆã€ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    if analysis.get("should_post", False):
                        # URLã‚’çŸ­ç¸®
                        short_url = url_shortener.shorten(url)
                        tweet_text = analyzer.generate_tweet_text(
                            title, analysis.get("summary"), analysis.get("theme"), short_url
                        )
                        add_to_post_queue(db, article.id, tweet_text)
                        queued_count += 1
                except Exception as e:
                    print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        return {
            "message": "DeepResearchå–å¾—ãƒ»åˆ†æå®Œäº†",
            "processed": processed_count,
            "analyzed": analyzed_count,
            "queued": queued_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¨ãƒ©ãƒ¼: {str(e)}")


@app.post("/fetch/analyze")
async def fetch_and_analyze(
    rss_url: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """è¨˜äº‹ã‚’å–å¾—ã—ã¦è‡ªå‹•åˆ†æï¼ˆRSSãƒ•ã‚£ãƒ¼ãƒ‰ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"""
    try:
        if rss_url:
            # æŒ‡å®šã•ã‚ŒãŸRSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å–å¾—
            articles = article_fetcher.fetch_from_rss(rss_url)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å–å¾—
            articles = feed_manager.fetch_all_feeds()
        
        processed_count = 0
        analyzed_count = 0
        queued_count = 0
        
        for article_data in articles:
            url = article_data['url']
            title = article_data['title']
            content = article_data.get('content', '')
            
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_article_by_url(db, url)
            if existing:
                continue
            
            # è¨˜äº‹ä½œæˆ
            article = create_article(
                db,
                url,
                title,
                content,
                article_data.get('published_at')
            )
            processed_count += 1
            
            # åˆ†æ
            try:
                analysis = analyzer.analyze_article(title, content, url)
                update_article_analysis(db, article.id, analysis)
                analyzed_count += 1
                
                # æŠ•ç¨¿å€™è£œã®å ´åˆã€ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                if analysis.get("should_post", False):
                    # URLã‚’çŸ­ç¸®
                    short_url = url_shortener.shorten(url)
                    tweet_text = analyzer.generate_tweet_text(
                        title, analysis.get("summary"), analysis.get("theme"), short_url
                    )
                    add_to_post_queue(db, article.id, tweet_text)
                    queued_count += 1
            except Exception as e:
                print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return {
            "message": "å–å¾—ãƒ»åˆ†æå®Œäº†",
            "processed": processed_count,
            "analyzed": analyzed_count,
            "queued": queued_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¨ãƒ©ãƒ¼: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

